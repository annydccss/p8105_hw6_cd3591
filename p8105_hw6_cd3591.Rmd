---
title: "p8105_hw6_cd3591"
author: "Anny"
date: "2025-11-28"
output: github_document
---

```{r}
# set up libraries
library(tidyverse)
```

# Problem 1
```{r}
# import the dataset
homicides_raw = read_csv("homicide-data.csv") %>% 
  janitor::clean_names()

# tidy the dataset
homicides = homicides_raw %>%
  mutate(
    city_state = str_c(city, ", ", state),  # e.g. “Baltimore, MD”
    resolved = ifelse(disposition == "Closed by arrest", 1, 0),  # 1 means homicide is solved, 0 means it is not (binary)
    victim_age = as.numeric(victim_age)  # Be sure that victim_age is numeric
  ) %>%
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),  
    # Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO, Tulsa, AL
    victim_race %in% c("White", "Black"),  # limit your analysis those for whom victim_race is white or black
    !is.na(victim_age)
  ) %>%
  mutate(
    victim_sex = relevel(factor(victim_sex), ref = "Female"),  # make the reference level is female in victim_sex
    victim_race = relevel(factor(victim_race), ref = "White")  # make the reference level is white in victim_race
  )
```

```{r}
# Baltimore only: OR + CI for male vs female
baltimore_fit = homicides %>%
  filter(city_state == "Baltimore, MD") %>%
  glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())

baltimore_or =
  broom::tidy(baltimore_fit, exponentiate = TRUE, conf.int = TRUE) %>%
  filter(term == "victim_sexMale") %>%
  select(estimate, conf.low, conf.high)

baltimore_or
```

The estimate of the ajusted OR is `r baltimore_or[1]`, with the confidence interval of (`r baltimore_or[2]`, `r baltimore_or[3]`).

```{r}
# run each city
city_or = homicides %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(
    fit = purrr::map(
      data,
      possibly(
        ~ suppressWarnings(glm(resolved ~ victim_age + victim_sex + victim_race,
              data = .x, family = binomial())),
        otherwise = NULL
      )
    ),
    tidied = purrr::map(
      fit,
      ~ if (is.null(.x)) NULL else suppressWarnings(broom::tidy(.x, exponentiate = TRUE, conf.int = TRUE))
    )
  ) %>%
  select(city_state, tidied) %>%
  filter(!map_lgl(tidied, is.null)) %>%      # drop cities where glm failed
  unnest(tidied) %>%
  filter(term == "victim_sexMale") %>%
  transmute(
    city_state,
    or = estimate,
    ci_low = conf.low,
    ci_high = conf.high
  ) %>%
  mutate(city_state = fct_reorder(city_state, or))

city_or
```

```{r}
# plot the graph of the estimated ORs and CIs for each city
ggplot(city_or, aes(x = city_state, y = or)) +
  geom_point() +
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0) +
  geom_hline(yintercept = 1, linetype = 2) +
  coord_flip() +
  theme_minimal() +
  labs(x = "City", y = "Adjusted OR (Male vs Female)")
```

Across most cities, the adjusted odds ratio (male vs. female) is below 1. This suggests that, after adjusting for victim age and race, homicides with male victims generally have lower odds of being solved than homicides with female victims.

A smaller number of cities have point estimates near 1 (or slightly above 1), indicating little difference by victim sex or a possible reversal in direction. However, many of these estimates have confidence intervals that cross 1, so the evidence for a clear sex difference in those cities is weak or inconclusive.

Finally, a few cities show very wide confidence intervals and/or unusually large odds ratios (e.g., the extreme value near the bottom of the plot). These patterns usually reflect limited data within that city complete separation in the logistic regression, which makes estimates unstable. As a result, those extreme city-specific estimates should be interpreted cautiously compared with the more precise estimates.

# Problem 2
```{r}
# get the weather_df
library(p8105.datasets)
data("weather_df")
```

```{r}
set.seed(1122)

# write the function for bootstrap
bootstrap = function(df) {
  boot_df = df %>% slice_sample(n = nrow(df), replace = TRUE)

  fit = lm(tmax ~ tmin + prcp, data = boot_df)

  r2 = broom::glance(fit)$r.squared

  coefs = broom::tidy(fit)
  b1 = coefs %>% filter(term == "tmin") %>% pull(estimate)
  b2 = coefs %>% filter(term == "prcp") %>% pull(estimate)

  tibble(r2 = r2, beta1_over_beta2 = b1 / b2)
}

# 5000 bootstrap replicates
boot_results = map_dfr(1:5000, ~ bootstrap(weather_df))
```

```{r}
# r^2 distribution
ggplot(boot_results, aes(x = r2)) +
  geom_histogram(bins = 40) +
  theme_minimal() +
  labs(title = "Bootstrap distribution of R-squared", x = "R-squared", y = "Count")
```

The bootstrap distribution of R_squared is unimodal, roughly bell-shaped and fairly narrow, centered around about 0.94. This indicates the model fit is very stable across bootstrap resamples: in almost every resample, the regression of tmax on tmin and prcp explains a very similar proportion of the variability in tmax (roughly 93%–95%).

```{r}
# beta1/beta2 distribution (can be extreme if beta2 is near 0)
ggplot(boot_results, aes(x = beta1_over_beta2)) +
  geom_histogram(bins = 60) +
  theme_minimal() +
  labs(title = "Bootstrap distribution of beta1/beta2", x = "beta1 / beta2", y = "Count")
```

The bootstrap distribution of b1/b2 is unimodal, much wider and clearly left-skewed. Most values cluster around a large negative number (roughly in the −200 range), but there is a long left tail extending to much more negative values (e.g., below −300 and even farther). This happens because the ratio becomes extremely negative in bootstrap samples where the estimated precipitation coefficient b2 is close to zero, which makes b1/b2 very sensitive to small changes in b2.

```{r}
# 95% bootstrap confidence intervals (2.5% and 97.5%)
ci_table =
  boot_results %>%
  summarise(
    r2_ci_low = quantile(r2, 0.025, na.rm = TRUE),
    r2_ci_high = quantile(r2, 0.975, na.rm = TRUE),
    ratio_ci_low = quantile(beta1_over_beta2, 0.025, na.rm = TRUE),
    ratio_ci_high = quantile(beta1_over_beta2, 0.975, na.rm = TRUE))

ci_table
```

For R_squared, the confidence interval is (`r ci_table[1]`, `r ci_table[2]`). For b1/b2, the confidence interval is (`r ci_table[3]`, `r ci_table[4]`).

# Problem 3
```{r}
# read the dataset
birthweight_raw = read_csv("birthweight.csv")

# clean the data
birthweight = birthweight_raw %>%
  janitor::clean_names() %>%   
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("male", "female")),
    malform = factor(malform, levels = c(0, 1), labels = c("absent", "present")),
    frace = factor(frace),
    mrace = factor(mrace)
  )

# check for the presence of missing data
na_table = birthweight %>%
  summarise(across(everything(), ~ sum(is.na(.x)))) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "n_missing") %>%
  arrange(desc(n_missing))

na_table
```

```{r}
# Propose a regression model for birthweight
fit = lm(bwt ~ blength + bhead + gaweeks + 
               babysex + smoken + delwt + wtgain + mheight,
  data = birthweight)
```

Description of modeling process: I chose predictors based on subject-matter plausibility: gestational age and newborn size measures (length and head circumference) should strongly relate to birthweight, and maternal smoking and maternal size/weight variables may also affect fetal growth. I then checked a residuals-versus-fitted plot to see whether residuals are roughly centered around 0 with no severe pattern.

```{r}
# show a plot of model residuals against fitted values
birthweight %>%
  modelr::add_predictions(fit) %>%
  modelr::add_residuals(fit) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, linetype = 2) +
  theme_minimal() +
  labs(x = "Fitted values", y = "Residuals",
       title = "Residuals vs Fitted: Proposed birthweight model")
```

The residuals vs fitted plot shows a dense cloud of points centered around the horizontal zero line, especially for fitted birthweights in the roughly 2500–3800 g range. In this main region, the residuals look fairly symmetric around 0 with no strong curvature pattern, which suggests the linear mean structure is broadly reasonable for the majority of observations.

However, the spread of residuals is not perfectly constant across the fitted values. There are several notable outliers, including some very large positive residuals at lower fitted values (meaning the model strongly under-predicts birthweight for a few cases), and some large negative residuals at higher fitted values (meaning the model over-predicts for a few cases). This indicates mild heteroscedasticity and the presence of influential or unusual observations.

```{r}
```